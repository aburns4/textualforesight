# -*- coding: utf-8 -*-
"""process_aitw.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SIE7DCq8EMvO5csxR5XycxGbc16744Vu

Copyright 2023 The Google Research Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

import sys
sys.path.append('./google-research')

from android_in_the_wild import visualization_utils
import argparse
import tensorflow as tf
import random
import json
import glob
import numpy as np
import time
import os
import random
import dask.bag as db
from dask.distributed import Client, LocalCluster, progress
from collections import defaultdict, Counter
from typing import List
from multiprocessing import freeze_support

GENERIC_WORDS = ['action', 'bar', 'menu', 'title', 'and', 'ans', 'app', 'icon', 'name',
                 'arg', 'background', 'element', 'btn', 'but', 'bottom', 'button', 'content',
                 'desc', 'text', 'item', 'empty', 'fab', 'image', 'grid', 'header', 'img',
                 'imgfile', 'lbutton', 'label', 'letter', 'list', 'view', 'pic', 'placeholder',
                 'random', 'row', 'single', 'raw', 'small', 'large', 'sub', 'template', 'navbar', 
                 'banner', 'test', 'textinput', 'error', 'texto', 'todo', 'toolbar', 'tool', 'track',
                 'txt', 'unknown', 'stub', 'web', 'left', 'right', 'tlb', 'nan', 'page', 'feature',
                 'menugrid', 'picture', 'tabs', 'number', 'node', 'iconimage', 'entity', 'webview',
                 'heading', 'logo', 'tbl', 'tab', 'primary', 'footer']

dataset_directories = {
    'general': 'gs://gresearch/android-in-the-wild/general/*',
    'google_apps': 'gs://gresearch/android-in-the-wild/google_apps/*',
    'install': 'gs://gresearch/android-in-the-wild/install/*',
    'single': 'gs://gresearch/android-in-the-wild/single/*',
    'web_shopping': 'gs://gresearch/android-in-the-wild/web_shopping/*',
}

parser = argparse.ArgumentParser('Create pretrain annotations for Spotlight objective')
parser.add_argument('--dataset',
                    type=str,
                    default="aitw",
                    help='specify which dataset to process')
parser.add_argument('--dataset_subset',
                    type=str,
                    choices=["general", "google_apps", "install", "web_shopping"],
                    help='specify which dataset subset to process')
parser.add_argument('--process_from_raw',
                    type=bool,
                    default=False,
                    help='whether to load raw view hierarchies (true) or finalize processing of intermediate jsons') 
parser.add_argument('--image_output_path',
                    type=str,
                    default="/scratch/aburns4/aitw",
                    help='where to store image byte files')
parser.add_argument('--counts_path',
                    type=str,
                    default="/projectnb2/ivc-ml/aburns4/LAVIS/pretrain_stuff/aitw_counts",
                    help='specify where to caption counts from')
parser.add_argument('--input_json_pattern',
                    nargs="+",
                    default="/projectnb2/ivc-ml/aburns4/LAVIS/pretrain_stuff/spotlight_jsons/aitw/raw_aitw_by_sub_dataset/gen*.json",
                    help='specify where to load intermediate json from')
parser.add_argument('--output_json_path',
                    type=str,
                    default="/projectnb2/ivc-ml/aburns4/LAVIS/pretrain_stuff/spotlight_jsons/aitw/aitw_by_app_thresholded",
                    help='specify where to store final jsons')
parser.add_argument('--output_counts_path',
                    type=str,
                    default="/projectnb2/ivc-ml/aburns4/LAVIS/pretrain_stuff/aitw_counts/",
                    help='specify where to store counts jsons')
parser.add_argument('--start_range',
                    type=int,
                    default=0,
                    help='specify start of range to process')
parser.add_argument('--end_range',
                    type=int,
                    default=5000,
                    help='specify end of range to process')
parser.add_argument('--index',
                    type=int,
                    default=0,
                    help='specify split index of current dataset to process')

def is_good_ocr(field):
  toks = field.split(' ')
  only_gen = (len(set(toks).difference(set(GENERIC_WORDS))) == 0)
  single_or_empty_char = (len(field) <= 1)
  is_url = (len(toks) == 1 and 'http' in field)
  transformed_field = field.encode('unicode-escape').decode('ascii')
  is_alpha = all(x.isalpha() or x.isspace() for x in transformed_field) # TODO: I think I fixed this, not sure if I want to allow numbers though
  if (not only_gen) and (not single_or_empty_char) and (not is_url) and is_alpha:
      return True
  return False

def process_aitw_sample(ex):
  samples = []

  app_id = ex.features.feature['current_activity'].bytes_list.value[0].decode('utf-8')
  # .split('/')[0]

  ui_locations = ex.features.feature['image/ui_annotations_positions'].float_list.value
  ui_locations = [ui_locations[i:i+4] for i in range(0, len(ui_locations), 4)]
  ui_text = ex.features.feature['image/ui_annotations_text'].bytes_list.value
  ui_types = ex.features.feature['image/ui_annotations_ui_types'].bytes_list.value

  screen_w = ex.features.feature['image/width'].int64_list.value[0]
  screen_h = ex.features.feature['image/height'].int64_list.value[0]
  n_channels = ex.features.feature['image/channels'].int64_list.value[0]

  kept_ocrs = []
  for loc, ocr, ui_type in zip(ui_locations, ui_text, ui_types):
    sample = {}
    
    if not ocr:
      ui_type = ui_type.decode('utf-8')
      if "ICON" in ui_type:
        ocr = " ".join(ui_type.split("_")[1:]).lower()
      else:
        print(ui_type)
    else:
      ocr = ocr.decode('utf-8')

    if ocr and is_good_ocr(ocr):
      loc_coord = [loc[1], loc[0], loc[1]+loc[3], loc[0]+loc[2]]
      img_id = "_".join(
          [ex.features.feature['episode_id'].bytes_list.value[0].decode('utf-8'),
           str(ex.features.feature['step_id'].int64_list.value[0])])

      sample["image_id"] = img_id
      sample["app_id"] = app_id

      sample["caption"] = ocr
      kept_ocrs.append(ocr)
      sample["screen_meta"] = [screen_w, screen_h, n_channels]
      sample["screen_norm_bbox"] = loc_coord

      samples.append(sample)
  return samples, len(ui_text), kept_ocrs

def get_counts(samples):
  counts = defaultdict(int)
  i = 0
  for entry in samples:
      if i % 100000 == 0:
          print(i)
      i+=1
      counts[entry["caption"]] += 1
  return counts

def merge_and_remove_infrequent(samples, counts, threshold=5):
    # remove text that occurs fewer than 5 times    
    app_bbox_text = []
    final_kept = []
    j = 0
    for sample in samples:
        if counts[sample['caption'].lower()] >= threshold:
            final_kept.append(sample)
            app_bbox_text.append((sample['app_id'], formatted_bbox, sample['caption']))

    print(len(app_bbox_text))
    print(len(set(app_bbox_text)))
    return final_kept

def main():
  start_time = time.time()

  global args
  args = parser.parse_args()
  
  potential_total = 0
  realized_total = 0
  caption_counts = defaultdict(int)
  if args.process_from_raw:
    dataset_name = args.dataset_subset
    filenames = tf.io.gfile.glob(dataset_directories[dataset_name])
    assert args.start_range >= 0 and args.start_range <= args.end_range
    
    filenames = filenames[args.start_range : args.end_range]
    print(args.start_range, args.end_range, len(filenames))
    raw_dataset = tf.data.TFRecordDataset(filenames, compression_type='GZIP').as_numpy_iterator()

    i = 0
    to_write = []
    map_imid_to_number = {}
    for d in raw_dataset:
      if i % 1000 == 0:
        print(i)
      
      ex = tf.train.Example()
      ex.ParseFromString(d)
      processed, curr_ptotal, captions = process_aitw_sample(ex)

      for cap in captions:
        caption_counts[cap] += 1

      potential_total += curr_ptotal
      realized_total += len(processed)
      to_write.extend(processed)
      
      file_map = "_".join([ex.features.feature['episode_id'].bytes_list.value[0].decode('utf-8'),
                            str(ex.features.feature['step_id'].int64_list.value[0])])
      map_imid_to_number[file_map] = i

      if not os.path.exists(args.image_output_path):
        os.makedirs(args.image_output_path)
      
      i+=1

    output_intermediate_dir = os.path.join('spotlight_jsons', args.dataset, "raw_aitw_by_sub_dataset")
    if not os.path.exists(output_intermediate_dir):
        os.makedirs(output_intermediate_dir)
    
    fn = "_".join([dataset_name, str(args.index), 'pretrain.json'])
    with open(os.path.join(output_intermediate_dir, fn), 'w') as f:
        json.dump(to_write, f)

    if not os.path.exists(args.output_counts_path):
        os.makedirs(args.output_counts_path)
    with open(os.path.join(args.output_counts_path, fn), 'w') as f:
        json.dump(caption_counts, f)
    
    end_time = time.time()
    seconds = end_time - start_time
    minutes = seconds / 60
    hours = minutes / 60
    print('%d possible annotations, only %d kept after processing text' % (potential_total, realized_total))
    print('Time to process leaf nodes of %s %s samples: %.2f seconds / %.2f minutes / %.2f / hours' % (i, args.dataset, seconds, minutes, hours))

  else:
    with open("/projectnb2/ivc-ml/aburns4/LAVIS/pretrain_stuff/aitw_counts/all_counts.json") as f:
      counts = json.load(f)

    paths = [p for pattern in args.input_json_pattern for p in glob.glob(pattern)]
    print(paths)
    removed = 0
    for p in paths:
        app_to_samples = defaultdict(list)
        with open(p) as f:
            data = json.load(f)
        for sample in data:
            if counts[sample["caption"].lower()] >= 5:
                sample["aitw_subset"] = p.split('/')[-1].split('_')[0]
                app_to_samples[sample["app_id"]].append(sample)
            else:
                removed += 1
    
        subdir = p.split('/')[-1].split("_pretrain.json")[0]
        print(subdir)
        if not os.path.exists(os.path.join(args.output_json_path, subdir)):
            os.makedirs(os.path.join(args.output_json_path, subdir))
        for app in app_to_samples:
            save_app_name = app.replace('/', '_')
            # very_large = ["com.android.settings_.SubSettings", "com.android.chrome_com.google.android.apps.chrome.Main",
            #               "com.android.chrome_org.chromium.chrome.browser.preferences.Preferences",
            #               "com.android.vending_com.android.vending.AssetBrowserActivity",
            #               "com.google.android.apps.maps_com.google.android.maps.MapsActivity"]
            # if save_app_name in very_large:
            #   rand_choice = random.randint(0,4)
            #   save_app_name += str(rand_choice)
            save_path = os.path.join(args.output_json_path, subdir, save_app_name + ".json")
            if os.path.exists(save_path):
                with open(save_path) as f:
                    curr_samples = json.load(f)

                combined = app_to_samples[app] + curr_samples
                with open(save_path, "w") as f:
                    json.dump(combined, f)
            else:
                with open(save_path, "w") as f:
                    json.dump(app_to_samples[app], f)
    print("Number of samples removed due to infrequency %d" % removed)

      # print(jsons_to_load)
      # jsons = []
      # for j in jsons_to_load:
      #     with open(j) as f:
      #         data = json.load(f)
      #         jsons.extend(data)
      # with open(args.counts_path) as f:
      #   all_counts = json.load(f)
      # cleaned = merge_and_remove_infrequent(jsons, all_counts)
      # with open(args.output_json_path, "w") as f:
      #     json.dump(cleaned, f)

if __name__ == "__main__":
  freeze_support()
  main()